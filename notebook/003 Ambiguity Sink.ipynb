{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b7c5f4e-e4c3-4689-95c3-8f8f026b4b54",
   "metadata": {},
   "source": [
    "# \"Ambiguity sink\" in remapping pipelines\n",
    "## A complementary phenomena to what is better described as \"ambiguity source\"\n",
    "### April 17th, 2025\n",
    "\n",
    "In pipelines with a step that involves remapping to consensus, an initial reference must be supplied. Genetic dissimilarity/divergence in this reference compared to the sample to be assembled can result in reads not being mapped. This can masquerade as dropout, or regions that failed to sequence, on the wet lab side. However, it's well-known that the chosen reference can bias an analysis. Choosing a more similar reference may result in more reads mapping to a homologous but more genetically similar region, showing that some dropped out regions may in fact be computational artifacts.\n",
    "\n",
    "In the current HPAI panzootic, there is an astonishing amount of circulating diversity even in geographically limited areas. This begs the question of how to choose a reference to assemble multiple samples from such a region. The idea behind remapping pipelines is that an initial reference can have a per-sample consensus called and remapped to. This new consensus sequence can ideally serve as exactly genetically similar to what is in the sample. However, this strategy is not without challenges. This notebook describes a complementary phenomena to yesterday's notebook. There, what could better be described as \"ambiguity source\" was explored: in regions of remapped consensus calls with stretches of ambiguous bases, without a fill-in step, these ambiguous regions can actually <i>slowly expand</i> upon each remapping step. Here we describe a complementary phenomena: with fill-in, these regions <i>slowly contract</i> with each remapping. This can be described as ambiguity sinking.\n",
    "\n",
    "This motivates the use of tools like [VAPOR](https://academic.oup.com/bioinformatics/article/36/6/1681/5613803). VAPOR takes a FASTQ dataset for an individual sample and a FASTA of candidate references as input, and outputs a single sequence to be used as a genetically similar reference for that sample. This is in contrast to using a single reference for an initial consensus call for every sample in an entire project. This notebooks shows that this dramatically accelerates filling in when compared with the strategy of multiple remappings, producing better consensus sequences with far less computation. However, even this strategy alone has it doubts. We raise the question: is a combination of VAPOR and multiple remappings to achieve maximum ambiguity sink the ideal strategy in the current HPAI panzootic?\n",
    "\n",
    "## Exploring VAPOR\n",
    "\n",
    "We start from the paired and unpaired forward and reverse reads from the `trimmomatic` step of the pipeline for the `ms_w2` `pa` replicate 1  from yesterday's analysis. They are concatenated and fed to VAPOR. We search for a suitable reference using PA sequences from [our NA build](https://github.com/moncla-lab/nextstrain-hpai-north-america/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d3e9d40-0ee2-4dac-8296-cfeb716f6a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading database sequences\n",
      "Got 4136 unique sequences\n",
      "Getting database kmers\n",
      "Got 81290 database kmers\n",
      "Filtering reads\n",
      "50009 of 818099 reads survived\n",
      "Building wDBG\n",
      "Got 48100 wdbg kmers\n",
      "Culling kmers with coverage under 5 \n",
      "3084 kmers remaining\n",
      "Classifying\n",
      "0.9995433789954338\t4348080.0\t2190\t1985.4246575342465\t50009\t>A/eagle/Virginia/W221222/2022\n"
     ]
    }
   ],
   "source": [
    "cat *.fastq > concat.fastq\n",
    "vapor.py -fq concat.fastq -fa aligned_pa.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875cdab1-9c9f-460d-a93b-0bae7234d2da",
   "metadata": {},
   "source": [
    "We then pluck this out to be used as a reference and run the core steps of the pipeline at present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f88a7d9-cd4d-4691-8989-4b8e265cb276",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings:\n",
      "  Output files: \"ref.*.bt2\"\n",
      "  Line rate: 6 (line is 64 bytes)\n",
      "  Lines per side: 1 (side is 64 bytes)\n",
      "  Offset rate: 4 (one in 16)\n",
      "  FTable chars: 10\n",
      "  Strings: unpacked\n",
      "  Max bucket size: default\n",
      "  Max bucket size, sqrt multiplier: default\n",
      "  Max bucket size, len divisor: 4\n",
      "  Difference-cover sample period: 1024\n",
      "  Endianness: little\n",
      "  Actual local endianness: little\n",
      "  Sanity checking: disabled\n",
      "  Assertions: disabled\n",
      "  Random seed: 0\n",
      "  Sizeofs: void*:8, int:4, long:8, size_t:8\n",
      "Input files DNA, FASTA:\n",
      "  reference.fasta\n",
      "Building a SMALL index\n",
      "Reading reference sizes\n",
      "  Time reading reference sizes: 00:00:00\n",
      "Calculating joined length\n",
      "Writing header\n",
      "Reserving space for joined string\n",
      "Joining reference sequences\n",
      "  Time to join reference sequences: 00:00:00\n",
      "bmax according to bmaxDivN setting: 547\n",
      "Using parameters --bmax 411 --dcv 1024\n",
      "  Doing ahead-of-time memory usage test\n",
      "  Passed!  Constructing with these parameters: --bmax 411 --dcv 1024\n",
      "Constructing suffix-array element generator\n",
      "Building DifferenceCoverSample\n",
      "  Building sPrime\n",
      "  Building sPrimeOrder\n",
      "  V-Sorting samples\n",
      "  V-Sorting samples time: 00:00:00\n",
      "  Allocating rank array\n",
      "  Ranking v-sort output\n",
      "  Ranking v-sort output time: 00:00:00\n",
      "  Invoking Larsson-Sadakane on ranks\n",
      "  Invoking Larsson-Sadakane on ranks time: 00:00:00\n",
      "  Sanity-checking and returning\n",
      "Building samples\n",
      "Reserving space for 12 sample suffixes\n",
      "Generating random suffixes\n",
      "QSorting 12 sample offsets, eliminating duplicates\n",
      "QSorting sample offsets, eliminating duplicates time: 00:00:00\n",
      "Multikey QSorting 12 samples\n",
      "  (Using difference cover)\n",
      "  Multikey QSorting samples time: 00:00:00\n",
      "Calculating bucket sizes\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Split 2, merged 7; iterating...\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Split 1, merged 1; iterating...\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Avg bucket size: 272.875 (target: 410)\n",
      "Converting suffix-array elements to index image\n",
      "Allocating ftab, absorbFtab\n",
      "Entering Ebwt loop\n",
      "Getting block 1 of 8\n",
      "  Reserving size (411) for bucket 1\n",
      "  Calculating Z arrays for bucket 1\n",
      "  Entering block accumulator loop for bucket 1:\n",
      "  bucket 1: 10%\n",
      "  bucket 1: 20%\n",
      "  bucket 1: 30%\n",
      "  bucket 1: 40%\n",
      "  bucket 1: 50%\n",
      "  bucket 1: 60%\n",
      "  bucket 1: 70%\n",
      "  bucket 1: 80%\n",
      "  bucket 1: 90%\n",
      "  bucket 1: 100%\n",
      "  Sorting block of length 173 for bucket 1\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 174 for bucket 1\n",
      "Getting block 2 of 8\n",
      "  Reserving size (411) for bucket 2\n",
      "  Calculating Z arrays for bucket 2\n",
      "  Entering block accumulator loop for bucket 2:\n",
      "  bucket 2: 10%\n",
      "  bucket 2: 20%\n",
      "  bucket 2: 30%\n",
      "  bucket 2: 40%\n",
      "  bucket 2: 50%\n",
      "  bucket 2: 60%\n",
      "  bucket 2: 70%\n",
      "  bucket 2: 80%\n",
      "  bucket 2: 90%\n",
      "  bucket 2: 100%\n",
      "  Sorting block of length 382 for bucket 2\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 383 for bucket 2\n",
      "Getting block 3 of 8\n",
      "  Reserving size (411) for bucket 3\n",
      "  Calculating Z arrays for bucket 3\n",
      "  Entering block accumulator loop for bucket 3:\n",
      "  bucket 3: 10%\n",
      "  bucket 3: 20%\n",
      "  bucket 3: 30%\n",
      "  bucket 3: 40%\n",
      "  bucket 3: 50%\n",
      "  bucket 3: 60%\n",
      "  bucket 3: 70%\n",
      "  bucket 3: 80%\n",
      "  bucket 3: 90%\n",
      "  bucket 3: 100%\n",
      "  Sorting block of length 180 for bucket 3\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 181 for bucket 3\n",
      "Getting block 4 of 8\n",
      "  Reserving size (411) for bucket 4\n",
      "  Calculating Z arrays for bucket 4\n",
      "  Entering block accumulator loop for bucket 4:\n",
      "  bucket 4: 10%\n",
      "  bucket 4: 20%\n",
      "  bucket 4: 30%\n",
      "  bucket 4: 40%\n",
      "  bucket 4: 50%\n",
      "  bucket 4: 60%\n",
      "  bucket 4: 70%\n",
      "  bucket 4: 80%\n",
      "  bucket 4: 90%\n",
      "  bucket 4: 100%\n",
      "  Sorting block of length 267 for bucket 4\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 268 for bucket 4\n",
      "Getting block 5 of 8\n",
      "  Reserving size (411) for bucket 5\n",
      "  Calculating Z arrays for bucket 5\n",
      "  Entering block accumulator loop for bucket 5:\n",
      "  bucket 5: 10%\n",
      "  bucket 5: 20%\n",
      "  bucket 5: 30%\n",
      "  bucket 5: 40%\n",
      "  bucket 5: 50%\n",
      "  bucket 5: 60%\n",
      "  bucket 5: 70%\n",
      "  bucket 5: 80%\n",
      "  bucket 5: 90%\n",
      "  bucket 5: 100%\n",
      "  Sorting block of length 296 for bucket 5\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 297 for bucket 5\n",
      "Getting block 6 of 8\n",
      "  Reserving size (411) for bucket 6\n",
      "  Calculating Z arrays for bucket 6\n",
      "  Entering block accumulator loop for bucket 6:\n",
      "  bucket 6: 10%\n",
      "  bucket 6: 20%\n",
      "  bucket 6: 30%\n",
      "  bucket 6: 40%\n",
      "  bucket 6: 50%\n",
      "  bucket 6: 60%\n",
      "  bucket 6: 70%\n",
      "  bucket 6: 80%\n",
      "  bucket 6: 90%\n",
      "  bucket 6: 100%\n",
      "  Sorting block of length 186 for bucket 6\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 187 for bucket 6\n",
      "Getting block 7 of 8\n",
      "  Reserving size (411) for bucket 7\n",
      "  Calculating Z arrays for bucket 7\n",
      "  Entering block accumulator loop for bucket 7:\n",
      "  bucket 7: 10%\n",
      "  bucket 7: 20%\n",
      "  bucket 7: 30%\n",
      "  bucket 7: 40%\n",
      "  bucket 7: 50%\n",
      "  bucket 7: 60%\n",
      "  bucket 7: 70%\n",
      "  bucket 7: 80%\n",
      "  bucket 7: 90%\n",
      "  bucket 7: 100%\n",
      "  Sorting block of length 357 for bucket 7\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 358 for bucket 7\n",
      "Getting block 8 of 8\n",
      "  Reserving size (411) for bucket 8\n",
      "  Calculating Z arrays for bucket 8\n",
      "  Entering block accumulator loop for bucket 8:\n",
      "  bucket 8: 10%\n",
      "  bucket 8: 20%\n",
      "  bucket 8: 30%\n",
      "  bucket 8: 40%\n",
      "  bucket 8: 50%\n",
      "  bucket 8: 60%\n",
      "  bucket 8: 70%\n",
      "  bucket 8: 80%\n",
      "  bucket 8: 90%\n",
      "  bucket 8: 100%\n",
      "  Sorting block of length 342 for bucket 8\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 343 for bucket 8\n",
      "Exited Ebwt loop\n",
      "fchr[A]: 0\n",
      "fchr[C]: 716\n",
      "fchr[G]: 1135\n",
      "fchr[T]: 1660\n",
      "fchr[$]: 2190\n",
      "Exiting Ebwt::buildToDisk()\n",
      "Returning from initFromVector\n",
      "Wrote 4195263 bytes to primary EBWT file: ref.1.bt2.tmp\n",
      "Wrote 552 bytes to secondary EBWT file: ref.2.bt2.tmp\n",
      "Re-opening _in1 and _in2 as input streams\n",
      "Returning from Ebwt constructor\n",
      "Headers:\n",
      "    len: 2190\n",
      "    bwtLen: 2191\n",
      "    sz: 548\n",
      "    bwtSz: 548\n",
      "    lineRate: 6\n",
      "    offRate: 4\n",
      "    offMask: 0xfffffff0\n",
      "    ftabChars: 10\n",
      "    eftabLen: 20\n",
      "    eftabSz: 80\n",
      "    ftabLen: 1048577\n",
      "    ftabSz: 4194308\n",
      "    offsLen: 137\n",
      "    offsSz: 548\n",
      "    lineSz: 64\n",
      "    sideSz: 64\n",
      "    sideBwtSz: 48\n",
      "    sideBwtLen: 192\n",
      "    numSides: 12\n",
      "    numLines: 12\n",
      "    ebwtTotLen: 768\n",
      "    ebwtTotSz: 768\n",
      "    color: 0\n",
      "    reverse: 0\n",
      "Total time for call to driver() for forward index: 00:00:00\n",
      "Reading reference sizes\n",
      "  Time reading reference sizes: 00:00:00\n",
      "Calculating joined length\n",
      "Writing header\n",
      "Reserving space for joined string\n",
      "Joining reference sequences\n",
      "  Time to join reference sequences: 00:00:00\n",
      "  Time to reverse reference sequence: 00:00:00\n",
      "bmax according to bmaxDivN setting: 547\n",
      "Using parameters --bmax 411 --dcv 1024\n",
      "  Doing ahead-of-time memory usage test\n",
      "  Passed!  Constructing with these parameters: --bmax 411 --dcv 1024\n",
      "Constructing suffix-array element generator\n",
      "Building DifferenceCoverSample\n",
      "  Building sPrime\n",
      "  Building sPrimeOrder\n",
      "  V-Sorting samples\n",
      "  V-Sorting samples time: 00:00:00\n",
      "  Allocating rank array\n",
      "  Ranking v-sort output\n",
      "  Ranking v-sort output time: 00:00:00\n",
      "  Invoking Larsson-Sadakane on ranks\n",
      "  Invoking Larsson-Sadakane on ranks time: 00:00:00\n",
      "  Sanity-checking and returning\n",
      "Building samples\n",
      "Reserving space for 12 sample suffixes\n",
      "Generating random suffixes\n",
      "QSorting 12 sample offsets, eliminating duplicates\n",
      "QSorting sample offsets, eliminating duplicates time: 00:00:00\n",
      "Multikey QSorting 12 samples\n",
      "  (Using difference cover)\n",
      "  Multikey QSorting samples time: 00:00:00\n",
      "Calculating bucket sizes\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Split 2, merged 7; iterating...\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Split 1, merged 1; iterating...\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Split 1, merged 1; iterating...\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Avg bucket size: 272.875 (target: 410)\n",
      "Converting suffix-array elements to index image\n",
      "Allocating ftab, absorbFtab\n",
      "Entering Ebwt loop\n",
      "Getting block 1 of 8\n",
      "  Reserving size (411) for bucket 1\n",
      "  Calculating Z arrays for bucket 1\n",
      "  Entering block accumulator loop for bucket 1:\n",
      "  bucket 1: 10%\n",
      "  bucket 1: 20%\n",
      "  bucket 1: 30%\n",
      "  bucket 1: 40%\n",
      "  bucket 1: 50%\n",
      "  bucket 1: 60%\n",
      "  bucket 1: 70%\n",
      "  bucket 1: 80%\n",
      "  bucket 1: 90%\n",
      "  bucket 1: 100%\n",
      "  Sorting block of length 365 for bucket 1\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 366 for bucket 1\n",
      "Getting block 2 of 8\n",
      "  Reserving size (411) for bucket 2\n",
      "  Calculating Z arrays for bucket 2\n",
      "  Entering block accumulator loop for bucket 2:\n",
      "  bucket 2: 10%\n",
      "  bucket 2: 20%\n",
      "  bucket 2: 30%\n",
      "  bucket 2: 40%\n",
      "  bucket 2: 50%\n",
      "  bucket 2: 60%\n",
      "  bucket 2: 70%\n",
      "  bucket 2: 80%\n",
      "  bucket 2: 90%\n",
      "  bucket 2: 100%\n",
      "  Sorting block of length 365 for bucket 2\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 366 for bucket 2\n",
      "Getting block 3 of 8\n",
      "  Reserving size (411) for bucket 3\n",
      "  Calculating Z arrays for bucket 3\n",
      "  Entering block accumulator loop for bucket 3:\n",
      "  bucket 3: 10%\n",
      "  bucket 3: 20%\n",
      "  bucket 3: 30%\n",
      "  bucket 3: 40%\n",
      "  bucket 3: 50%\n",
      "  bucket 3: 60%\n",
      "  bucket 3: 70%\n",
      "  bucket 3: 80%\n",
      "  bucket 3: 90%\n",
      "  bucket 3: 100%\n",
      "  Sorting block of length 280 for bucket 3\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 281 for bucket 3\n",
      "Getting block 4 of 8\n",
      "  Reserving size (411) for bucket 4\n",
      "  Calculating Z arrays for bucket 4\n",
      "  Entering block accumulator loop for bucket 4:\n",
      "  bucket 4: 10%\n",
      "  bucket 4: 20%\n",
      "  bucket 4: 30%\n",
      "  bucket 4: 40%\n",
      "  bucket 4: 50%\n",
      "  bucket 4: 60%\n",
      "  bucket 4: 70%\n",
      "  bucket 4: 80%\n",
      "  bucket 4: 90%\n",
      "  bucket 4: 100%\n",
      "  Sorting block of length 168 for bucket 4\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 169 for bucket 4\n",
      "Getting block 5 of 8\n",
      "  Reserving size (411) for bucket 5\n",
      "  Calculating Z arrays for bucket 5\n",
      "  Entering block accumulator loop for bucket 5:\n",
      "  bucket 5: 10%\n",
      "  bucket 5: 20%\n",
      "  bucket 5: 30%\n",
      "  bucket 5: 40%\n",
      "  bucket 5: 50%\n",
      "  bucket 5: 60%\n",
      "  bucket 5: 70%\n",
      "  bucket 5: 80%\n",
      "  bucket 5: 90%\n",
      "  bucket 5: 100%\n",
      "  Sorting block of length 273 for bucket 5\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 274 for bucket 5\n",
      "Getting block 6 of 8\n",
      "  Reserving size (411) for bucket 6\n",
      "  Calculating Z arrays for bucket 6\n",
      "  Entering block accumulator loop for bucket 6:\n",
      "  bucket 6: 10%\n",
      "  bucket 6: 20%\n",
      "  bucket 6: 30%\n",
      "  bucket 6: 40%\n",
      "  bucket 6: 50%\n",
      "  bucket 6: 60%\n",
      "  bucket 6: 70%\n",
      "  bucket 6: 80%\n",
      "  bucket 6: 90%\n",
      "  bucket 6: 100%\n",
      "  Sorting block of length 320 for bucket 6\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 321 for bucket 6\n",
      "Getting block 7 of 8\n",
      "  Reserving size (411) for bucket 7\n",
      "  Calculating Z arrays for bucket 7\n",
      "  Entering block accumulator loop for bucket 7:\n",
      "  bucket 7: 10%\n",
      "  bucket 7: 20%\n",
      "  bucket 7: 30%\n",
      "  bucket 7: 40%\n",
      "  bucket 7: 50%\n",
      "  bucket 7: 60%\n",
      "  bucket 7: 70%\n",
      "  bucket 7: 80%\n",
      "  bucket 7: 90%\n",
      "  bucket 7: 100%\n",
      "  Sorting block of length 380 for bucket 7\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 381 for bucket 7\n",
      "Getting block 8 of 8\n",
      "  Reserving size (411) for bucket 8\n",
      "  Calculating Z arrays for bucket 8\n",
      "  Entering block accumulator loop for bucket 8:\n",
      "  bucket 8: 10%\n",
      "  bucket 8: 20%\n",
      "  bucket 8: 30%\n",
      "  bucket 8: 40%\n",
      "  bucket 8: 50%\n",
      "  bucket 8: 60%\n",
      "  bucket 8: 70%\n",
      "  bucket 8: 80%\n",
      "  bucket 8: 90%\n",
      "  bucket 8: 100%\n",
      "  Sorting block of length 32 for bucket 8\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 33 for bucket 8\n",
      "Exited Ebwt loop\n",
      "fchr[A]: 0\n",
      "fchr[C]: 716\n",
      "fchr[G]: 1135\n",
      "fchr[T]: 1660\n",
      "fchr[$]: 2190\n",
      "Exiting Ebwt::buildToDisk()\n",
      "Returning from initFromVector\n",
      "Wrote 4195263 bytes to primary EBWT file: ref.rev.1.bt2.tmp\n",
      "Wrote 552 bytes to secondary EBWT file: ref.rev.2.bt2.tmp\n",
      "Re-opening _in1 and _in2 as input streams\n",
      "Returning from Ebwt constructor\n",
      "Headers:\n",
      "    len: 2190\n",
      "    bwtLen: 2191\n",
      "    sz: 548\n",
      "    bwtSz: 548\n",
      "    lineRate: 6\n",
      "    offRate: 4\n",
      "    offMask: 0xfffffff0\n",
      "    ftabChars: 10\n",
      "    eftabLen: 20\n",
      "    eftabSz: 80\n",
      "    ftabLen: 1048577\n",
      "    ftabSz: 4194308\n",
      "    offsLen: 137\n",
      "    offsSz: 548\n",
      "    lineSz: 64\n",
      "    sideSz: 64\n",
      "    sideBwtSz: 48\n",
      "    sideBwtLen: 192\n",
      "    numSides: 12\n",
      "    numLines: 12\n",
      "    ebwtTotLen: 768\n",
      "    ebwtTotSz: 768\n",
      "    color: 0\n",
      "    reverse: 1\n",
      "Total time for backward call to driver() for mirror index: 00:00:00\n",
      "Renaming ref.3.bt2.tmp to ref.3.bt2\n",
      "Renaming ref.4.bt2.tmp to ref.4.bt2\n",
      "Renaming ref.1.bt2.tmp to ref.1.bt2\n",
      "Renaming ref.2.bt2.tmp to ref.2.bt2\n",
      "Renaming ref.rev.1.bt2.tmp to ref.rev.1.bt2\n",
      "Renaming ref.rev.2.bt2.tmp to ref.rev.2.bt2\n",
      "458248 reads; of these:\n",
      "  359851 (78.53%) were paired; of these:\n",
      "    338025 (93.93%) aligned concordantly 0 times\n",
      "    21767 (6.05%) aligned concordantly exactly 1 time\n",
      "    59 (0.02%) aligned concordantly >1 times\n",
      "    ----\n",
      "    338025 pairs aligned concordantly 0 times; of these:\n",
      "      135 (0.04%) aligned discordantly 1 time\n",
      "    ----\n",
      "    337890 pairs aligned 0 times concordantly or discordantly; of these:\n",
      "      675780 mates make up the pairs; of these:\n",
      "        675774 (100.00%) aligned 0 times\n",
      "        6 (0.00%) aligned exactly 1 time\n",
      "        0 (0.00%) aligned >1 times\n",
      "  98397 (21.47%) were unpaired; of these:\n",
      "    92088 (93.59%) aligned 0 times\n",
      "    6302 (6.40%) aligned exactly 1 time\n",
      "    7 (0.01%) aligned >1 times\n",
      "6.14% overall alignment rate\n",
      "[mpileup] 1 samples in 1 input files\n",
      "Minimum Quality: 30\n",
      "Threshold: 0\n",
      "Minimum depth: 50\n",
      "Minimum Insert Threshold: 0.8\n",
      "Regions with depth less than minimum depth covered by: N\n",
      "Reference length: 2190\n",
      "Positions with 0 depth: 0\n",
      "Positions with depth below 50: 80\n"
     ]
    }
   ],
   "source": [
    "seqkit grep -p 'A/eagle/Virginia/W221222/2022' aligned_pa.fasta > reference.fasta\n",
    "\n",
    "bowtie2-build reference.fasta ref \n",
    "bowtie2 --local --very-sensitive-local -x ref -1 forward_paired.fastq -2 reverse_paired.fastq -U forward_unpaired.fastq,reverse_unpaired.fastq -S mapped.sam\n",
    "\n",
    "samtools view -S -b mapped.sam > mapped.bam\n",
    "samtools sort mapped.bam -o sorted.bam\n",
    "samtools index sorted.bam\n",
    "samtools mpileup -A -B -Q 0 -d 100000 -f reference.fasta sorted.bam > pileup.txt\n",
    "\n",
    "cat pileup.txt | ivar consensus -p ivar -m 50 -q 30 -t .0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f4aac3-297c-4d3c-a748-7d58b0b10e34",
   "metadata": {},
   "source": [
    "Multiple remappings were implemented as follows, making adjusts to the rules to call sample consensus and call consensus in batches:\n",
    "\n",
    "    +NUMBER_OF_REMAPPINGS = 3\n",
    "    +\n",
    "     wildcard_constraints:\n",
    "       segment=\"[^/]+\",\n",
    "       sample=\"[^/]+\",\n",
    "    @@ -184,10 +186,10 @@ rule trimmomatic:\n",
    "     def situate_reference_input(wildcards):\n",
    "         if wildcards.mapping_stage == 'initial':\n",
    "             return 'data/reference/sequences.fasta'\n",
    "    -    elif wildcards.mapping_stage == 'remapping':\n",
    "    +    elif wildcards.mapping_stage == 'remapping-1':\n",
    "             return f'data/{wildcards.sample}/replicate-{wildcards.replicate}/initial/filler.fasta'\n",
    "    -    else:\n",
    "    -        return f'data/{wildcards.sample}/replicate-{wildcards.replicate}/remapping/filler.fasta'\n",
    "    +    mapping_stage_int = int(wildcards.mapping_stage.split('-')[1]) - 1\n",
    "    +    return f'data/{wildcards.sample}/replicate-{wildcards.replicate}/remapping-{mapping_stage_int}/filler.fasta'\n",
    "     \n",
    "     \n",
    "     rule situate_reference:\n",
    "    @@ -441,7 +443,7 @@ rule fill_consensus:\n",
    "     \n",
    "     def call_sample_consensus_input(wildcards):\n",
    "         return expand(\n",
    "    -        'data/{{sample}}/replicate-{replicate}/reremapping/consensus.fasta',\n",
    "    +        f'data/{{sample}}/replicate-{replicate}/remapping-{NUMBER_OF_REMAPPINGS}/consensus.fasta',\n",
    "             replicate=metadata_dictionary[wildcards.sample].keys()\n",
    "         )\n",
    "     \n",
    "    @@ -582,7 +584,7 @@ def full_consensus_summary_input(wildcards):\n",
    "         for replicate in replicates.keys():\n",
    "             for segment in SEGMENTS:\n",
    "                 consensus_filepaths.append(\n",
    "    -                f'data/{wildcards.sample}/replicate-{replicate}/reremapping/segments/{segment}/consensus-report.tsv'\n",
    "    +                f'data/{wildcards.sample}/replicate-{replicate}/remapping-{NUMBER_OF_REMAPPINGS}/segments/{segment}/consensus-report.tsv'\n",
    "                 )\n",
    "         return consensus_filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c585bc-3179-4718-be27-e3fafaab324f",
   "metadata": {},
   "source": [
    "Below we display \n",
    "\n",
    "- three remappings from a sequence that is diverged from our initial reference\n",
    "- an initial consensus called with VAPOR's reference without any remapping at all\n",
    "\n",
    "<img src=\"images/003-three-remappings-vs-vapor.png\" width=\"1140\">\n",
    "\n",
    "This shows that the reference selected by VAPOR manages to call an additional ~400 bp than the third remapping, and that the remapping strategy as implemented at present only calls about an additional dozen bases per remapping as implemented at present.\n",
    "\n",
    "It also raises the following questions\n",
    "- Would remapping help resolve the ~60 bp region near 1105-1175?\n",
    "- Is there <b>still</b> signal hidden amongst this noise?\n",
    "- How many remappings would be necessary?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
